{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## ***Analisando os preços das casas de Melbourne.***\n",
        "\n",
        "dataset tirado do link:\n",
        "https://www.kaggle.com/dataset/dansbecker/melbourne-housing-snapshot?select=melb_data.csv\n",
        "\n",
        "Queremos saber qual é o melhor modelo de ML para se trabalhar com esse conjunto de dados."
      ],
      "metadata": {
        "id": "t0tjmTMnGTu4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qF3Dm5g3FSEf"
      },
      "outputs": [],
      "source": [
        "# IMPORTANDO AS BIBLIOTECAS\n",
        "# Tratamento dos dados\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "#from pandas_profiling import ProfileReport\n",
        "pd.options.display.float_format = '{:,.2f}'.format\n",
        "%matplotlib inline\n",
        "\n",
        "base = pd.read_csv(\"melb_data.csv\")\n",
        "\n",
        "# Vou retirar as colunas que tiveram uma alta cardinalidade\n",
        "base = base.drop(['Suburb', 'Address','SellerG', 'Date'], axis=1)\n",
        "\n",
        "# Tambem vou retirar as colunas que apresentam mais de 20% de valores nulos\n",
        "base = base.drop(['BuildingArea','YearBuilt'], axis=1)\n",
        "\n",
        "base.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrando a correlação entr as variáveis\n",
        "\n",
        "plt.figure(figsize=(13,8))\n",
        "sns.heatmap(base.corr(),annot=True, cmap='icefire')\n",
        "plt.show()\n",
        "\n",
        "# Nesse caso não iremos usar as variáveis de texto, mas se precisassemos bastava tratá-las para variáveis numéricas."
      ],
      "metadata": {
        "id": "fivVOnU3NziD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vou escolher apenas as colunas que tiveram as correlações mais altas e Landsize pois retirei a BuildingArea.\n",
        "\n",
        "base1 = base[['Price', 'Rooms', 'Bathroom', 'Bedroom2', 'Car', 'Landsize']]\n",
        "print(base1.info(), '\\n\\n')\n",
        "\n",
        "# Ainda existem valores vazios na coluna 'car'\n",
        "\n",
        "# Irei tratar esses valores apenas retirando as linhas com valores nulos, já que não são muitos valores\n",
        "\n",
        "base1 = base1.dropna(axis=0)\n",
        "print(base1.info())"
      ],
      "metadata": {
        "id": "XRrsRQ75X9wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Criando os modelos de ML**"
      ],
      "metadata": {
        "id": "nFu9Cqe0a7KC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# O primeiro passo é separar a nossa variável que queremos prever (y) e quais vão ser as colunas que iremos usar para essa predição (x)\n",
        "\n",
        "Y = base1.Price\n",
        "X = base1.drop('Price', axis=1)\n",
        "\n",
        "# Em seguida irei separar em treino e teste"
      ],
      "metadata": {
        "id": "EAJYUg1pahtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   A base de treino vai ser usada para treinar o modelo para que ele faça as previsões\n",
        "*   A base de teste vai ser usada para, ao usar o modelo já treinado, verificar o erro da previsão já feita pelo modelo em relação aos valores reais.\n",
        "\n"
      ],
      "metadata": {
        "id": "vlhUL62KcpMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_treino, x_teste, y_treino, y_teste = train_test_split(X,Y)\n",
        "\n",
        "# O próximo passo é escolher o modelo que iremos usar."
      ],
      "metadata": {
        "id": "cS31Xl3wdLaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regressão Linear"
      ],
      "metadata": {
        "id": "XJS0JTqzeRzO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando e instanciando o modelo\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "modelo = LinearRegression()\n",
        "\n",
        "# Fit do modelo\n",
        "modelo = modelo.fit(x_treino, y_treino)\n",
        "\n",
        "# Prevendo os dados de teste usando o modelo\n",
        "y_regressao = modelo.predict(x_teste)\n",
        "\n",
        "# podemos visualizar os pontos: previstos X real\n",
        "plt.figure(figsize=(6,6))\n",
        "sns.scatterplot(x=y_teste.values/1000000, y=y_regressao/1000000)\n",
        "plt.ylim(0,10)\n",
        "plt.xlim(0,10)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DNpLZsooeU8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Para avaliar o modelo, precisamos calcular os erros\n",
        "\n",
        "# Avaliando o erro quadrático médio\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "erro_quadratico = mean_squared_error(y_teste, y_regressao)\n",
        "print(erro_quadratico)\n",
        "\n",
        "# Avaliando o R quadrado\n",
        "from sklearn.metrics import r2_score\n",
        "r2_regressao = r2_score(y_teste, y_regressao)\n",
        "print(r2_regressao)"
      ],
      "metadata": {
        "id": "FHwQ8cGsi55z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regressão Linear: Selecionando outras colunas"
      ],
      "metadata": {
        "id": "M1poH_JLkHFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base2 = base[['Price', 'Rooms', 'Bathroom', 'Bedroom2', 'Car', 'Longtitude', 'Lattitude','Distance', 'Landsize', 'Postcode', 'Propertycount']]\n",
        "base2 = base2.dropna(axis=0)\n",
        "base2.info()"
      ],
      "metadata": {
        "id": "qjapz8-0kx9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.ma.core import mean\n",
        "# Vamos fazer as mesmas etapas que fizemos anteriormente\n",
        "\n",
        "# Separando a base\n",
        "y = base2.Price\n",
        "x = base2.drop('Price', axis=1)\n",
        "\n",
        "# Treino e teste\n",
        "x_treino, x_teste, y_treino, y_teste = train_test_split(x,y)\n",
        "\n",
        "# Fit para os novos modelos\n",
        "modelo2 = LinearRegression()\n",
        "\n",
        "# FIT\n",
        "modelo2 = modelo2.fit(x_treino, y_treino)\n",
        "\n",
        "# Usando o modelo para prever os dados de teste\n",
        "y_regressao2 = modelo2.predict(x_teste)\n",
        "\n",
        "# Avaliando os erros\n",
        "# Erro quadrátivo médio\n",
        "erro_quadratico2 = mean_squared_error(y_teste, y_regressao2)\n",
        "print(erro_quadratico2)\n",
        "\n",
        "# R quadrado\n",
        "r2_regressao2 = r2_score(y_teste, y_regressao2)\n",
        "print(r2_regressao2, '\\n\\n')\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "sns.scatterplot(x=y_teste.values/1000000, y=y_regressao2/1000000)\n",
        "plt.ylim(0,10)\n",
        "plt.xlim(0,10)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Z1zmevw8mObz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Árvore de decisão\n",
        "\n",
        "\n",
        "*   Vamos usar o mesmo treino e teste da base anterior\n",
        "\n"
      ],
      "metadata": {
        "id": "eJV8VrQmqfie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando o modelo\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "modelo_tree = DecisionTreeRegressor()\n",
        "\n",
        "modelo_tree = modelo_tree.fit(x_treino, y_treino)\n",
        "\n",
        "y_tree = modelo_tree.predict(x_teste)\n",
        "\n",
        "# Erro quadrático médio\n",
        "erro_quadratico_tree = mean_squared_error(y_teste, y_tree)\n",
        "print(erro_quadratico_tree)\n",
        "\n",
        "# R quadrado\n",
        "r2_tree = r2_score(y_teste, y_tree)\n",
        "print(r2_tree)"
      ],
      "metadata": {
        "id": "4tVWsREiqknv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resultados"
      ],
      "metadata": {
        "id": "jwHSB4jmsfVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Regressão Linear')\n",
        "print('Erro quadrático médio: ' + str(round(erro_quadratico, 2)))\n",
        "print('R quadrado: ' + str(round(r2_regressao, 4)))\n",
        "print('----------------------------------------------------------')\n",
        "print('Regressão Linear: Novas features')\n",
        "print('Erro quadrático médio: ' + str(round(erro_quadratico2, 2)))\n",
        "print('R quadrado: ' + str(round(r2_regressao2, 4)))\n",
        "print('----------------------------------------------------------')\n",
        "print('Árvore de Decisão')\n",
        "print('Erro quadrático médio: ' + str(round(erro_quadratico_tree, 2)))\n",
        "print('R quadrado: ' + str(round(r2_tree, 4)))\n",
        "print('----------------------------------------------------------')"
      ],
      "metadata": {
        "id": "aS5p9OoAsejB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclui-se que o modelo de árvore de decisão seria o melhor modelo para se estar trabalhando neste conjunto de dados por ser o que mais se aproxima do valor 1."
      ],
      "metadata": {
        "id": "oVzFekpUt_Vu"
      }
    }
  ]
}